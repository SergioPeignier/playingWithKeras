{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "\n",
    "# number of convolutional filters to use\n",
    "filters = 64\n",
    "\n",
    "# convolution kernel size\n",
    "num_conv = 3\n",
    "\n",
    "batch_size = 100\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_img_size = (img_chns, img_rows, img_cols)\n",
    "else:\n",
    "    original_img_size = (img_rows, img_cols, img_chns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MNIST Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train.shape:', (60000, 28, 28, 1))\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n",
    "\n",
    "print('x_train.shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to shape of multivariate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray([x_train[i,:,:,:].reshape(28*28) for i in range(x_train.shape[0])])\n",
    "x_test = np.asarray([x_test[i,:,:,:].reshape(28*28) for i in range(x_test.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM\n",
    "Without \"return sequence\" not \"stateful\" parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "lstm_1 = LSTM(32)(x)\n",
    "model = Model(x,lstm_1)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:30].reshape(3,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple stateful LSTM\n",
    "Without \"return sequence\"\n",
    "Stateful LSTM share their internal states between examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28),batch_shape=(3,10,28*28))\n",
    "lstm_1 = LSTM(32,\n",
    "              stateful=True)(x)\n",
    "model = Model(x,lstm_1)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:30].reshape(3,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple return sequence LSTM \n",
    "Without \"stateful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "lstm_2 = LSTM(32, return_sequences=True)(x)\n",
    "model = Model(x,lstm_2)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:10].reshape(1,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "lstm_2 = LSTM(32, return_sequences=True)(x)\n",
    "lstm_3 = LSTM(15, return_sequences=True)(lstm_2)\n",
    "lstm_4 = LSTM(5)(lstm_3)\n",
    "model = Model(x,lstm_4)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:10].reshape(1,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "conv_1 = Conv1D(filters=1, \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(x)\n",
    "#max_pooling_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "#lstm_1 = LSTM(100)(max_pooling_1)\n",
    "model = Model(x,conv_1)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n",
      "(1, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "print model.predict(x_train[0:10].reshape(1,10,784)).shape\n",
    "print x_train[0:10].reshape(1,10,784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 10, 784)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 10, 1)             1569      \n",
      "=================================================================\n",
      "Total params: 1,569\n",
      "Trainable params: 1,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 784, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.get_weights():\n",
    "        print layer.get_weights()[0].shape, layer.get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet1D + MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "conv_1 = Conv1D(filters=1, \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(x)\n",
    "max_pooling_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "#lstm_1 = LSTM(100)(max_pooling_1)\n",
    "model = Model(x,max_pooling_1)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 10, 784)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10, 1)             1569      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 1)              0         \n",
      "=================================================================\n",
      "Total params: 1,569\n",
      "Trainable params: 1,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 784, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.get_weights():\n",
    "        print layer.get_weights()[0].shape, layer.get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 1)\n",
      "(1, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "print model.predict(x_train[0:10].reshape(1,10,784)).shape\n",
    "print x_train[0:10].reshape(1,10,784).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxpooling and upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(10,28*28))\n",
    "max_pooling_1 = MaxPooling1D(pool_size=2)(x)\n",
    "upsampling_1 = UpSampling1D(size=2)(max_pooling_1)\n",
    "model = Model(x,upsampling_1)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 784)\n",
      "(1, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "print model.predict(x_train[0:10].reshape(1,10,784)).shape\n",
    "print x_train[0:10].reshape(1,10,784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 10, 784)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5, 784)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 10, 784)           0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.get_weights():\n",
    "        print layer.get_weights()[0].shape, layer.get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "input_dim = 28*28\n",
    "latent_dim = 100\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 10, 1), (1, 100))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:10].reshape(1,10,784)).shape, encoder.predict(x_train[0:10].reshape(1,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "input_dim = 28*28\n",
    "latent_dim = 100\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded_h1 = LSTM(300, return_sequences=True)(inputs)\n",
    "encoded = LSTM(latent_dim)(encoded_h1)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded_h1 = LSTM(300, return_sequences=True)(decoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded_h1)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 10, 1), (1, 100))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:10].reshape(1,10,784)).shape, encoder.predict(x_train[0:10].reshape(1,10,784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Auto Encoder with ConvNet1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "input_dim = 28*28\n",
    "latent_dim = 100\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "conv_1 = Conv1D(filters=300, \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(inputs)\n",
    "max_pooling_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "encoded_h1 = LSTM(300, return_sequences=True)(max_pooling_1)\n",
    "\n",
    "encoded = LSTM(latent_dim)(encoded_h1)\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "\n",
    "#upsampling_1 = UpSampling1D(size=2)(decoded)\n",
    "deconv_1 = Conv1D(filters=300, \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(decoded)\n",
    "decoded_h1 = LSTM(300, return_sequences=True)(deconv_1)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded_h1)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "sequence_autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 784)\n",
      "(1, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "print sequence_autoencoder.predict(x_train[0:10].reshape(1,10,784)).shape\n",
    "print x_train[0:10].reshape(1,10,784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 10, 784)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 10, 300)           470700    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 5, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "repeat_vector_17 (RepeatVect (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 10, 300)           60300     \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 10, 300)           721200    \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 10, 784)           3402560   \n",
      "=================================================================\n",
      "Total params: 5,536,360\n",
      "Trainable params: 5,536,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Sequential Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean_squash):\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean_squash = K.flatten(x_decoded_mean_squash)\n",
    "    xent_loss = img_rows * img_cols * metrics.binary_crossentropy(x, x_decoded_mean_squash)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# number of convolutional filters to use\n",
    "filters = 64\n",
    "# batch size\n",
    "batch_size = 100\n",
    "# number of latent dimensions\n",
    "latent_dim = 2\n",
    "# number of intermediate dimensins\n",
    "intermediate_dim = 128\n",
    "# std for variational model\n",
    "epsilon_std = 0.01\n",
    "# epochs\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "input_dim = 28*28\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "conv_1 = Conv1D(filters=300\n",
    "                , \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(inputs)\n",
    "max_pooling_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "encoded_h1 = LSTM(300, return_sequences=True)(max_pooling_1)\n",
    "encoded = LSTM(200)(encoded_h1)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(encoded)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_hid = Dense(intermediate_dim, activation='relu')(z)\n",
    "decoded = RepeatVector(timesteps)(decoder_hid)\n",
    "deconv_1 = Conv1D(filters=300, \n",
    "                kernel_size=2, \n",
    "                padding='same', \n",
    "                activation='relu')(decoded)\n",
    "decoded_h1 = LSTM(300, return_sequences=True)(deconv_1)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded_h1)\n",
    "\n",
    "sequence_encoder = Model(inputs, z_mean)\n",
    "sequence_encoder.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "sequence_autoencoder.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "print sequence_encoder.predict(x_train[0:10].reshape(1,10,784)).shape\n",
    "print x_train[0:10].reshape(1,10,784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 10, 784)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 10, 300)           470700    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 5, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 5, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 200)               400800    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,618,686\n",
      "Trainable params: 1,618,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_41 (InputLayer)            (None, 10, 784)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)               (None, 10, 300)       470700      input_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D)  (None, 5, 300)        0           conv1d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_92 (LSTM)                   (None, 5, 300)        721200      max_pooling1d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_93 (LSTM)                   (None, 200)           400800      lstm_92[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 128)           25728       lstm_93[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 2)             258         dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 2)             258         dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 2)             0           dense_22[0][0]                   \n",
      "                                                                   dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 128)           384         lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_23 (RepeatVector)  (None, 10, 128)       0           dense_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)               (None, 10, 300)       77100       repeat_vector_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_94 (LSTM)                   (None, 10, 300)       721200      conv1d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_95 (LSTM)                   (None, 10, 784)       3402560     lstm_94[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 5,820,188\n",
      "Trainable params: 5,820,188\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
